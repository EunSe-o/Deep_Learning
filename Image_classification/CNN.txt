<CNN에 관해서>

CNN이란 이미지를 인식하기 위해 패턴을 찾는데 특히 유용하다. 데이터에서 직접 학습하고 패턴을 사용해 이미지를 분류한다. 즉, 특징을 수동으로 추출할 필요가 없다. 이러한 장점 때문에 자율주행자동차, 얼굴인식과 같은 객체인식 등에 많이 사용된다.

CNN이 나오기 이전의 이미지 인식은 2차원으로 된 이미지를 1차원 배열로 바꾼 뒤, FC 신경망으로 학습시키는 방법이었다. (예를 들어 원인지 타원인지는 고려하지 않고, raw data를 직접 처리하기 때문에 많은 양의 학습 데이터가 필요하고 학습시간이 길어진다. 또한 이미지가 회전하거나 움직이면 새로운 입력으로 데이터를 처리해주어야 한다. 이미지의 특성을 이해하지 못하고 단순 1D 데이터로 보고 학습하는 것이 특징이다.) 이러한 단점을 보완하여 이미지의 공간정보를 유지한채 학습을 하게하는 모델이 CNN이다.

CNN의 가장 핵심적인 개념은 이미지의 공간정보를 유지한채 학습을 한다는 것이다.

*이미지 처리에서 자주 등장하는 sobel filter는 이미지의 가로 세로 특징을 뽑아낼 수 있는 필터이다. 어떠한 이미지에 이 필터들을 차례대로 적용시키면 sobel-x를 적용한 이미지에서는 세로선이 나타나고 sobel-y를 적용한 이미지에서는 가로선이 나타난다. 그리고 이 둘을 합치면 원본의 이미지가 나타나게 된다. 
이처럼 CNN에서도 여러 개의 필터를 이용해 이미지의 세부 특징을 추출해서 학습할 수 있다.
CNN은 신경망에서 학습을 통해 자동으로 적합한 필터를 생성해준다.

multi Channel CNN에서 주의해야 할 점
1. input data의 channel수와 filter의 channel수는 같아야 함 (예를들어 그림처럼 3ch가 input이라면 filter도 3channel)
2. input data의 channel의 수와 관계없이 filter의 개수만큼 output데이터가 나옴

*입력 데이터보다 출력 데이터가 작아지는 것을 방지하는 방법이 Padding 이다.
zero padding : 0으로 둘러싸는 padding. 
zero padding을 사용하면 convolution해도 크기가 작아지지 않는다. 

*이미지 분류에서의 CNN 구조

Input: 이미지

-특징 추출 단계(Feature Extraction)
#Convolution Layer : 필터를 통해 이미지의 특징을 추출.
#Pooling Layer : 특징을 강화시키고 이미지의 크기를 줄임. (즉, 사소한 변화를 무시함)
(Convolution과 Pooling을 반복하면서 이미지의 feature를 추출)

-이미지 분류 단계(Classification)
#Flatten Layer : 데이터 타입을 FC네트워크 형태로 변경. 입력데이터의 shape 변경만 수행.
#Softmax Layer : Classification수행.
Output : 인식결과

*CNN의 매개변수
#Convolution Filter의 개수
각 Layer에서의 연산시간/량을 비교적 일정하게 유지하며 시스템의 균형을 맞추는 것이 좋습니다.
보통 Pooling Layer를 거치면 1/4로 출력이 줄어들기 때문에 Convolution Layer의 결과인 Feature Map의 개수를 4배정도 증가시키면 됩니다.

#Filter의 사이즈
작은 필터를 여러개 중첩하면 원하는 특징을 더 돋보이게하면서 연산량을 줄일 수 있습니다.
요즘 대부분의 CNN은 3x3 size를 중첩해서 사용한다고 합니다.

#Padding여부
Padding은 Convolution을 수행하기 전, 입력 데이터 주변을 특정 픽셀 값으로 채워 늘리는 것입니다.
Padding을 사용하게 되면 입력 이미지의 크기를 줄이지 않을 수 있습니다.

#Stride
Stride는 Filter의 이동 간격을 조절하는 매개변수입니다.
이 값이 커지게 되면 결과 데이터의 사이즈가 작아지게 됩니다.

결과적으로 CNN은 convolution과 pooling을 반복적으로 사용하면서 불변하는 특징을 찾고, 그 특징을 입력데이터로 Fully-connected 신경망에 보내 Classification을 수행한다.

-----------------------------------------------------------------------------
*데이터 정규화 (Data Normalization)

정규화되지 않은 데이터셋은 타원모양으로 길게 늘어져 Learning Rate를 매우 작게 해야지만 학습이 가능하다. 만약 충분히 작지 않다면 수평, 수직으로 이동할 때 불균형이 발생하여 Gradient Descent 알고리즘을 적용하기 어려울 수 있다.
반면 정규화된 데이터셋은 구 모양이므로 Gradient Descent 알고리즘을 적용하여 쉬복 빠르게 최적화 지점을 찾을 수 있다.

*데이터 정규화 방법
1. Normalization(Min/Max)
전체 구간을 [0,1]로 맞춘다.

2. Standardization

original data : 정규화 하기 전의 데이터 분포
zero-centered data : 원 데이터에 평균을 뺌. 이로써 데이터의 분포가 가운데에 모이게 됩니다.
normalized data : 표준편차를 나눠줌으로써 데이터의 분포가 일정해지는 효과를 얻게 됩니다. (가로 세로 길이가 같아짐)
*이미지 분류 데이터 부풀리기 (데이터 셋 부풀리기)
굳이 다른 사진을 찾는 것이 아니라 1개 사진마다 각도를 바꾸고, 옆으로 조금씩 이동시키는 등의 변화를 줄 수 있다.

-----------------------------------------------------------------------------
첫번째 작업은 분류 작업으로, 이미지가 물체를 포함하고 있다는것을 가정한 상태에서 그냥 분류만 하면 된다.
두번째는 지역화(Localization)이 포함된 개념으로 물체에 바운딩 박스를 그려준다.
물체 탐지 (Object Detection)은 사진에서 다량의 물체를 바운딩 박스를 쳐가고 이의 물체에 대해 분간하는 작업으로 통칭 불린다. 이정도면 자율주행까지도 가능하다.
객체 분류 (Instance Segmentation)은 통칭 픽셀마다 물체를 탐지하여 이를 마스킹 해주는 작업까지 포함되어있다.

* R-CNN (Regional Convolution Neural Network)
R-CNN은 물체가 있을만한 공간을 Region이라 하고 이 Region을 각각의 CNN을 태워 feature를 뽑고 최종적으로 SVM을 통해 물체가 무엇인지 구별한다.
일단 사진이 주어진 상태에서, 물체가 있을만한 공간을 뒤져야 한다. 이 후보 공간들을 제시해주는 과정이 Region Proposal 이라고 말해보자.
